{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import glob\n",
    "import os\n",
    "from datetime import timedelta\n",
    "\n",
    "# sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, minmax_scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# machine learning\n",
    "from lightgbm import LGBMRegressor\n",
    "from fbprophet import Prophet\n",
    "\n",
    "\n",
    "# plots\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('seaborn-ticks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `read COVID-19 datasets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data/*.csv'\n",
    "files = glob.glob(os.path.join(path))\n",
    "print (files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "for f in files:\n",
    "    filename = f.split('\\\\')[-1].split('.')[0]\n",
    "    d = pd.read_csv(f, encoding='utf-8')\n",
    "    datasets[filename] = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'covid_19_data'\n",
    "datasets[key].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fillna values -> 0 [confirmed, deaths, recovered] -> astype INT\n",
    "cols = ['Confirmed', 'Deaths', 'Recovered']\n",
    "for c in cols:\n",
    "    datasets[key][c] = datasets[key][c].fillna(0)\n",
    "    datasets[key][c] = datasets[key][c].astype(int)\n",
    "    \n",
    "datasets[key].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build date\n",
    "datasets[key]['Date'] = pd.to_datetime(datasets[key]['ObservationDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `create dataframe`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[key]['Country/Region'] = [\n",
    "    ' '.join(i.split()).strip() for i in datasets[key]['Country/Region']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = datasets[key].groupby(['Country/Region', 'Date']) \\\n",
    "    .agg({'Confirmed': sum}) \\\n",
    "    .reset_index()\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix names\n",
    "df.loc[df['Country/Region'] == 'US', 'Country/Region'] = 'United States'\n",
    "df.loc[df['Country/Region'] == 'Mainland China', 'Country/Region'] = 'China'\n",
    "df.loc[df['Country/Region'] == 'UK', 'Country/Region'] = 'United Kingdom'\n",
    "df.loc[df['Country/Region'] == 'Czechia', 'Country/Region'] = 'Czech Republic'\n",
    "df.loc[df['Country/Region'] == 'Taiwan*', 'Country/Region'] = 'Taiwan'\n",
    "df.loc[df['Country/Region'] == 'Viet Nam', 'Country/Region'] = 'Vietnam'\n",
    "df.loc[df['Country/Region'] == 'occupied Palestinian territory', 'Country/Region'] = 'Palestine'\n",
    "df.loc[df['Country/Region'] == \"('St. Martin',)\", 'Country/Region'] = 'St. Martin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove Cruise Ship\n",
    "df = df[~ df['Country/Region'].isin(['Cruise Ship', 'Others'])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by=['Country/Region', 'Date']) \\\n",
    "    .reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix dates -> adding missing intervals\n",
    "store_frames = []\n",
    "\n",
    "# create time frame\n",
    "default = pd.date_range(\n",
    "    start=sorted(df['Date'].tolist())[0],\n",
    "    end=sorted(df['Date'].tolist())[-1],\n",
    "    freq='D'\n",
    ").values\n",
    "default = [pd.to_datetime(i) for i in default]\n",
    "\n",
    "# iterate over countries\n",
    "for country in df['Country/Region'].unique():\n",
    "    d = df[df['Country/Region'] == country]\n",
    "    serie = sorted(d['Date'].tolist())\n",
    "    s1 = serie[0]\n",
    "    idx = default.index(s1)\n",
    "    \n",
    "    # check if series match in length\n",
    "    match = len(serie) == len(default)\n",
    "    if not match:\n",
    "        \n",
    "        # temporal dataframe\n",
    "        tmp = pd.DataFrame(\n",
    "            {\n",
    "                'Date': default\n",
    "            }\n",
    "        )\n",
    "        tmp['Country/Region'] = country\n",
    "        \n",
    "        # merge frames\n",
    "        d = tmp.merge(d, how='left') \\\n",
    "            .reset_index(drop=True)\n",
    "        \n",
    "        # iterate rows\n",
    "        for row in range(d.shape[0]):\n",
    "            if row < idx:\n",
    "                d['Confirmed'].iloc[row] = 0\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        d['Confirmed'] = d['Confirmed'].fillna(method='ffill')\n",
    "        d['Confirmed'] = d['Confirmed'].astype(int)                \n",
    "    \n",
    "    # Fix confirmed cases\n",
    "    values = d['Confirmed'].tolist()\n",
    "    store_values = []\n",
    "    i = 0\n",
    "    N = d.shape[0]\n",
    "    store_values.append(values[i])\n",
    "    for j in values:\n",
    "        if i + 1 != N:\n",
    "            v1 = store_values[i]\n",
    "            v2 = values[i + 1]\n",
    "            if v2 < v1:\n",
    "                v2 = v1\n",
    "        \n",
    "            # sotore value\n",
    "            store_values.append(v2)\n",
    "            i += 1\n",
    "    \n",
    "    # add values\n",
    "    d['Confirmed'] = store_values\n",
    "    \n",
    "    # Min Max scale\n",
    "    d['Confirmed_scale'] = minmax_scale(d['Confirmed'])\n",
    "    \n",
    "    # store frame\n",
    "    store_frames.append(d)\n",
    "\n",
    "# concat frames\n",
    "df = pd.concat(store_frames, sort=True) \\\n",
    "    .sort_values(by=['Country/Region', 'Date']) \\\n",
    "    .reset_index(drop=True)\n",
    "\n",
    "# add outbreak\n",
    "df['Outbreak'] = 'COVID-19'\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N countries\n",
    "df['Country/Region'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `add new data  ---> manually`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Country/Region'] == 'India'][['Date', 'Confirmed']].tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_data(d, main):\n",
    "    '''\n",
    "    '''\n",
    "    m = main.copy()\n",
    "    d = pd.DataFrame(d)\n",
    "    d['Date'] = pd.to_datetime(d['Date'])\n",
    "    \n",
    "    return pd.concat([m, d], sort=True) \\\n",
    "            .sort_values(by=['Country/Region', 'Date']) \\\n",
    "            .reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = [\n",
    "    {\n",
    "        'Date': '2020-04-07',\n",
    "        'Country/Region': 'India',\n",
    "        'Confirmed': 103942,\n",
    "        'Confirmed_scale': 0,\n",
    "        'Outbreak': 'COVID-19'\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_new_data(new_data, df)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Prophet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df[df['Country/Region'] == 'India'].copy()\n",
    "sample['cases'] = sample['Confirmed'].diff().fillna(0)\n",
    "\n",
    "cap = sample[sample['Date'] > '2020-03-31']['cases'].mean() * 30\n",
    "print (cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df[df['Country/Region'] == 'India'][['Date', 'Confirmed']].reset_index(drop=True)\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['Confirmed'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['ds'] = sample['Date']\n",
    "sample['y'] = sample['Confirmed']\n",
    "\n",
    "# delete old columns\n",
    "del sample['Date']\n",
    "del sample['Confirmed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['floor'] = 0\n",
    "sample['cap'] = cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = Prophet(\n",
    "    growth='logistic',\n",
    "    interval_width=0.98,\n",
    "    daily_seasonality=True,\n",
    "    weekly_seasonality=False,\n",
    "    yearly_seasonality=False,\n",
    "    seasonality_mode='additive'\n",
    ")\n",
    "\n",
    "M.fit(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future = M.make_future_dataframe(periods=30)\n",
    "future['floor'] = 0\n",
    "future['cap'] = cap\n",
    "future.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = M.predict(future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnfrm = forecast.loc[:, ['ds','trend']]\n",
    "cnfrm = cnfrm[cnfrm['trend'] > 0]\n",
    "cnfrm[cnfrm['ds'] > '2020-04-07'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = cnfrm[cnfrm['ds'] > '2020-04-07'].copy()\n",
    "preds.index = pd.DatetimeIndex(preds['ds'], name='index')\n",
    "del preds['ds']\n",
    "\n",
    "preds.name = 'ML Model'\n",
    "preds['predicted'] = preds['trend'].astype(int)\n",
    "del preds['trend']\n",
    "\n",
    "# sample\n",
    "preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = sample[['ds', 'y']].copy()\n",
    "actual.columns = ['ds', 'trend']\n",
    "actual.index = pd.DatetimeIndex(actual['ds'], name='index')\n",
    "del actual['ds']\n",
    "\n",
    "actual.name = 'Historical data'\n",
    "actual['trend'] = actual['trend'].astype(int)\n",
    "\n",
    "# sample\n",
    "actual.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`PLOT`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 9))\n",
    "\n",
    "actual.plot(ax=ax, marker='o', linewidth=2.5)\n",
    "preds.plot(ax=ax, marker='o', color='#FDA50F', linewidth=2)\n",
    "plt.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.legend(fontsize=20)\n",
    "ax.set_xlabel('')\n",
    "plt.box(False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.to_excel('c:/i/workspace/DFRLab/Research/_builder/assets/20200330COVIDMex/IndiaForecast30days.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD FORECAST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Get SARS data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sars_data = datasets['sars_2003_complete_dataset_clean']\n",
    "sars_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sars_data['Outbreak'] = 'SARS_2003'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sars_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "sars_data.rename(\n",
    "    {\n",
    "        'Cumulative number of case(s)': 'Confirmed',\n",
    "        'Country': 'Country/Region',\n",
    "    }, axis=1, inplace=True\n",
    ")\n",
    "\n",
    "sars_data['Date'] = pd.to_datetime(sars_data['Date'])\n",
    "sars_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix countries names\n",
    "sars_data['Country/Region'] = [' '.join(i.split()).strip() for i in sars_data['Country/Region']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix names\n",
    "sars_data.loc[sars_data['Country/Region'] == 'Taiwan, China', 'Country/Region'] = 'Taiwan'\n",
    "sars_data.loc[sars_data['Country/Region'] == 'Hong Kong SAR, China', 'Country/Region'] = 'Hong Kong'\n",
    "sars_data.loc[sars_data['Country/Region'] == 'Russian Federation', 'Country/Region'] = 'Russia'\n",
    "sars_data.loc[sars_data['Country/Region'] == 'Viet Nam', 'Country/Region'] = 'Vietnam'\n",
    "sars_data.loc[sars_data['Country/Region'] == 'Macao SAR, China', 'Country/Region'] = 'Macau'\n",
    "sars_data.loc[sars_data['Country/Region'] == 'Republic of Korea', 'Country/Region'] = 'South Korea'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sars_data_filter = sars_data[['Country/Region', 'Date', 'Confirmed', 'Outbreak']]\n",
    "sars_data_filter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix cumulative number of cases\n",
    "sars_frames = []\n",
    "for c in sars_data_filter['Country/Region'].unique():\n",
    "    d = sars_data_filter[sars_data_filter['Country/Region'] == c]\n",
    "    values = d['Confirmed'].tolist()\n",
    "    store_values = []\n",
    "    i = 0\n",
    "    N = d.shape[0]\n",
    "    store_values.append(values[i])\n",
    "    for j in values:\n",
    "        if i + 1 != N:\n",
    "            v1 = store_values[i]\n",
    "            v2 = values[i + 1]\n",
    "            if v2 < v1:\n",
    "                v2 = v1\n",
    "        \n",
    "            # sotore value\n",
    "            store_values.append(v2)\n",
    "            i += 1\n",
    "            \n",
    "    # change values in Confirmed cases\n",
    "    d['Confirmed'] = store_values\n",
    "    \n",
    "    # Min Max scale\n",
    "    d['Confirmed_scale'] = minmax_scale(d['Confirmed'])\n",
    "    \n",
    "    # store new frames\n",
    "    sars_frames.append(d)\n",
    "    \n",
    "# concat new frames\n",
    "sars = pd.concat(sars_frames, sort=True) \\\n",
    "    .sort_values(by=['Country/Region', 'Date']) \\\n",
    "    .reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sars[sars['Country/Region'] == 'Australia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Build datasets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df_ = pd.concat([df, sars], sort=True) \\\n",
    "    .sort_values(by=['Country/Region', 'Date']) \\\n",
    "    .reset_index(drop=True)\n",
    "\n",
    "_df_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove countries with minor confirmation cases\n",
    "t = _df_.groupby('Country/Region') \\\n",
    "    .agg({'Confirmed': max})\n",
    "t = t.loc[t['Confirmed'] > 50]\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df_ = pd.merge(_df_, t[[]], left_on=['Country/Region'], right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df_.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # sort data\n",
    "    _df_ = _df_.sort_values(by=['Country/Region', 'Date']) \\\n",
    "        .reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # remove extra row in China\n",
    "    _df_ = _df_.drop(562)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort data\n",
    "data = _df_.sort_values(by=['Country/Region', 'Date']) \\\n",
    "    .reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataset\n",
    "data.to_excel('./data/countries.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Build new dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix, ax = plt.subplots(figsize=(16, 6), ncols=2)\n",
    "s0 = data['Confirmed']\n",
    "s0.plot.hist(ax=ax[0]);\n",
    "\n",
    "# sklearn preprocessing\n",
    "transformer = MinMaxScaler(feature_range=(0, 1)).fit(np.asarray([0, 2e5]).reshape(-1, 1))\n",
    "s1 = pd.Series(transformer.transform(s0.values.reshape(-1, 1)).reshape(-1))\n",
    "s1.plot.hist(ax=ax[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add tranform data to dataset\n",
    "data['Confirmed_transformed'] = s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Date preprocessing`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Month'] = data['Date'].dt.month\n",
    "data['Week'] = data['Date'].dt.week\n",
    "data['Day'] = data['Date'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `merge new data to countries`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_data = datasets['countries of the world']\n",
    "countries_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean countries names\n",
    "countries_data['Country'] = [' '.join(i.split()).strip() for i in countries_data['Country']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find countries not match\n",
    "countries_ls = [\n",
    "    i for i in data['Country/Region'].unique().tolist()\n",
    "    if i not in countries_data['Country'].unique().tolist()\n",
    "]\n",
    "len(countries_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_data = countries_data[~ countries_data['Country'].isin(countries_ls)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[~ data['Country/Region'].isin(countries_ls)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    countries_ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # change country name\n",
    "    countries_data.loc[countries_data['Country'] == 'Korea, South', 'Country'] = 'South Korea'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # find countries not match\n",
    "    countries_ls = [\n",
    "        i for i in data['Country/Region'].unique().tolist()\n",
    "        if i not in countries_data['Country'].unique().tolist()\n",
    "    ]\n",
    "    len(countries_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match countries\n",
    "match_countries = [\n",
    "    i for i in countries_data['Country'].unique().tolist()\n",
    "    if i in data['Country/Region'].unique().tolist()\n",
    "]\n",
    "len(match_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_df = countries_data[countries_data['Country'].isin(match_countries)].copy()\n",
    "countries_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename country field\n",
    "countries_df['Country/Region'] = countries_df['Country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge\n",
    "data = data.merge(countries_df, on='Country/Region')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix Pop. Density (per sq. mi.) and Net migration\n",
    "data['Pop. Density (per sq. mi.)'] = [float(i.replace(',', '.')) for i in data['Pop. Density (per sq. mi.)']]\n",
    "data['Net migration'] = [float(i.replace(',', '.')) for i in data['Net migration']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Lags`\n",
    "\n",
    "> Lag is expressed in a time unit (e.g. in minutes) and corresponds to the amount of data history we allow the model to use when making the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_lags = 5\n",
    "for k, v in data.groupby('Country/Region'):\n",
    "    for i in range(n_lags, 0, -1):\n",
    "        data.loc[v.index, f'Confirmed_Lag_{i}'] = v['Confirmed'].shift(i)\n",
    "        data.loc[v.index, f'Confirmed_Rolling_Mean_Lag_{i}'] = v['Confirmed'].shift(i).rolling(n_lags).mean()\n",
    "        data.loc[v.index, f'Confirmed_Transformed_Lag_{i}'] = v['Confirmed_transformed'].shift(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get specific columns\n",
    "X_mask_lags = sorted([c for c in data.columns if ('Lag' in c and not 'Transformed' in c)])\n",
    "X_mask_tranformed_lags = [c for c in data.columns if 'Transformed_Lag' in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fillna columns --> 0\n",
    "data[X_mask_lags] = data[X_mask_lags].fillna(0)\n",
    "data[X_mask_tranformed_lags] = data[X_mask_tranformed_lags].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "data[X_mask_lags].tail(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Encoding`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# country\n",
    "encoding_country = LabelEncoder().fit(data['Country/Region'])\n",
    "data['Country_encoding'] = encoding_country.transform(data['Country/Region'])\n",
    "\n",
    "# region\n",
    "# encoding_region = LabelEncoder().fit(data['Region'])\n",
    "# data['Region_encoding'] = encoding_region.transform(data['Region'])\n",
    "\n",
    "# outbreak\n",
    "encoding_outbreak = LabelEncoder().fit(data['Outbreak'])\n",
    "data['Outbreak_encoding'] = encoding_outbreak.transform(data['Outbreak'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resave data\n",
    "data.to_excel('./data/countries_lags.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Machine Learning --> LGBM`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = train_test_split(data.loc[data['Confirmed'] > 1000], test_size=0.2, shuffle=True, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgbm = LGBMRegressor(n_estimators=500, metric='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_mask_cat = ['Month', 'Week', 'Outbreak_encoding', 'Region_encoding']\n",
    "X_mask_cat = ['Month', 'Week', 'Outbreak_encoding']\n",
    "X_cols = X_mask_cat + sorted(X_mask_lags[:n_lags], reverse=True) + sorted(X_mask_lags[n_lags:], reverse=True)\n",
    "Y = train['Confirmed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgbm.fit(\n",
    "    X=train[X_cols],\n",
    "    y=Y,\n",
    "    eval_set=(valid[X_cols], valid['Confirmed']),\n",
    "    early_stopping_rounds=500,\n",
    "    verbose=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Exploratory`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "    tmp = data[data['Outbreak'] == 'COVID-19']\n",
    "    g = sns.FacetGrid(tmp, col='Country/Region', hue='Country/Region',\n",
    "                      sharey=False, col_wrap=5)\n",
    "    g.map(plt.plot, 'Date', 'Confirmed')\n",
    "    g.set_xticklabels(rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Machine Learning --> Prediction`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (sorted(data['Country/Region'].unique().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = 'United States'\n",
    "data[\n",
    "    (data['Country/Region'] == country) &\n",
    "    (data['Outbreak'] == 'COVID-19')\n",
    "]['Confirmed'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_steps = 20\n",
    "\n",
    "# historical data\n",
    "history = data.loc[\n",
    "    (data['Country/Region'] == country) &\n",
    "    (data['Outbreak'] == 'COVID-19')\n",
    "]\n",
    "history_ending = history.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_rng = pd.date_range(\n",
    "    start=history_ending['Date'] + timedelta(days=1),\n",
    "    end=history_ending['Date'] + timedelta(days=pred_steps),\n",
    "    freq='D'\n",
    ").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_months = pd.Series(dt_rng).apply(lambda dt: dt.month)\n",
    "pred_weeks = pd.Series(dt_rng).apply(lambda dt: dt.week)\n",
    "pred_days = pd.Series(dt_rng).apply(lambda dt: dt.day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_mask_cat & X_mask_lags --> get arrays from values\n",
    "pred_cat = history_ending[X_mask_cat].values\n",
    "pred_lags = history_ending[X_mask_lags].values\n",
    "\n",
    "y = history_ending['Confirmed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final value\n",
    "print (f'Final value --> {y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('History ending cat', pred_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('History ending lags', pred_lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Specific process - changing lags`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*`lags int`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray(sorted(pred_lags[:n_lags]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.roll(np.asarray(sorted(pred_lags[:n_lags])), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lags[:n_lags] = np.roll(np.asarray(sorted(pred_lags[:n_lags])), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lags[:n_lags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lags[n_lags - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lags[n_lags - 1] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lags[:n_lags]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*`lags mean`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray(sorted(pred_lags[n_lags:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.roll(np.asarray(sorted(pred_lags[n_lags:])), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lags[n_lags:] = np.roll(np.asarray(sorted(pred_lags[n_lags:])), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lags[n_lags:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lags[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(pred_lags[:n_lags])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lags[-1] = np.mean(pred_lags[:n_lags])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lags[n_lags:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build np zeros array\n",
    "pred = np.zeros(pred_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pred_cat ---> ['Month', 'Week', 'Outbreak_encoding', 'Region_encoding', 'Confirmed_scale', 'cum_sum']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(pred_steps):     \n",
    "    pred_cat[0] = pred_months[i]\n",
    "    pred_cat[1] = pred_weeks[i]\n",
    "    \n",
    "    y = model_lgbm.predict(np.hstack([pred_cat, pred_lags]).reshape(1, -1))[0]\n",
    "    print(f'Predicted was: {y}')\n",
    "    \n",
    "    pred_lags[:n_lags] = np.roll(pred_lags[:n_lags], -1)\n",
    "    \n",
    "    # Lag\n",
    "    pred_lags[n_lags-1] = y\n",
    "    pred_lags[n_lags:] = np.roll(pred_lags[n_lags:], -1)\n",
    "    \n",
    "    # rolling_mean\n",
    "    pred_lags[-1] = np.mean(pred_lags[n_lags:])\n",
    "\n",
    "    pred[i] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.Series(data=pred, index=dt_rng, name='LGBM Regressor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history[['Date', 'Confirmed']].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Plot Forecast`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 9))\n",
    "\n",
    "hist = history.set_index(['Date'])['Confirmed'].plot(ax=ax, marker='o')\n",
    "preds.plot(ax=ax, marker='.', color='#FDA50F')\n",
    "plt.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "ax.set_xlabel('')\n",
    "plt.box(False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Save data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save output\n",
    "output_path = f'./data/20200321Outputs/output_{\"_\".join(country.split(\",\"))}.xlsx'\n",
    "preds.to_excel(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
